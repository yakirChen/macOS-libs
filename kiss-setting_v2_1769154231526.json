{
  "darkMode": "auto",
  "uiLang": "zh",
  "minLength": 2,
  "maxLength": 100000,
  "newlineLength": 20,
  "httpTimeout": 10000,
  "clearCache": false,
  "injectRules": true,
  "fabClickAction": 0,
  "contextMenuType": 1,
  "subrulesList": [
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules_v2.json",
      "selected": true
    },
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules-on_v2.json",
      "selected": false
    },
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules-off_v2.json",
      "selected": false
    }
  ],
  "transApis": [
    {
      "apiSlug": "BuiltinAI",
      "apiName": "BuiltinAI",
      "apiType": "BuiltinAI",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Google",
      "apiName": "Google",
      "apiType": "Google",
      "url": "https://translate.googleapis.com/translate_a/single",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Google2",
      "apiName": "Google2",
      "apiType": "Google2",
      "url": "https://translate-pa.googleapis.com/v1/translateHtml",
      "key": "AIzaSyATBXajvzQLTDHEQbcpq0Ihe0vWDHmO520",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Microsoft",
      "apiName": "Microsoft",
      "apiType": "Microsoft",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "AzureAI",
      "apiName": "AzureAI",
      "apiType": "AzureAI",
      "url": "https://api.cognitive.microsofttranslator.com/translate?api-version=3.0",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Tencent",
      "apiName": "Tencent",
      "apiType": "Tencent",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Volcengine",
      "apiName": "Volcengine",
      "apiType": "Volcengine",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepL",
      "apiName": "DeepL",
      "apiType": "DeepL",
      "url": "https://api-free.deepl.com/v2/translate",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepLFree",
      "apiName": "DeepLFree",
      "apiType": "DeepLFree",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 1,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepLX",
      "apiName": "DeepLX",
      "apiType": "DeepLX",
      "url": "http://localhost:1188/translate",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "NiuTrans",
      "apiName": "NiuTrans",
      "apiType": "NiuTrans",
      "url": "https://api.niutrans.com/NiuTransServer/translation",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": "",
      "dictNo": "",
      "memoryNo": ""
    },
    {
      "apiSlug": "OpenAI",
      "apiName": "OpenAI",
      "apiType": "OpenAI",
      "url": "https://api.openai.com/v1/chat/completions",
      "key": "",
      "model": "gpt-4",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Gemini",
      "apiName": "Gemini",
      "apiType": "Gemini",
      "url": "https://generativelanguage.googleapis.com/v1/models/{{model}}:generateContent?key={{key}}",
      "key": "",
      "model": "gemini-2.5-flash",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Gemini2",
      "apiName": "Gemini2",
      "apiType": "Gemini2",
      "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
      "key": "",
      "model": "gemini-2.0-flash",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Claude",
      "apiName": "Claude",
      "apiType": "Claude",
      "url": "https://api.anthropic.com/v1/messages",
      "key": "",
      "model": "claude-3-haiku-20240307",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "CloudflareAI",
      "apiName": "CloudflareAI",
      "apiType": "CloudflareAI",
      "url": "https://api.cloudflare.com/client/v4/accounts/{{ACCOUNT_ID}}/ai/run/@cf/meta/m2m100-1.2b",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Ollama",
      "apiName": "Ollama",
      "apiType": "Ollama",
      "url": "http://192.168.1.66:11434/api/chat",
      "key": "",
      "model": "gpt-oss:120b",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "OpenRouter",
      "apiName": "OpenRouter",
      "apiType": "OpenRouter",
      "url": "https://openrouter.ai/api/v1/chat/completions",
      "key": "",
      "model": "openai/gpt-4o",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Custom",
      "apiName": "Custom",
      "apiType": "Custom",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "async (args, { url, body, headers, userMsg, method } = {}) => {\n  console.log(\"request hook args:\", { args, url, body, headers, userMsg, method });\n  // return { url, body, headers, userMsg, method };\n};",
      "resHook": "async ({ res, ...args }) => {\n  console.log(\"reaponse hook args:\", { res, args });\n  // const translations = [[\"你好\", \"zh\"]];\n  // const modelMsg = \"\";\n  // return { translations, modelMsg };\n};",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "OpenAI_99da3420-d49f-42da-966b-a5a233a9c50c",
      "apiName": "longcat",
      "apiType": "OpenAI",
      "url": "https://api.longcat.chat/openai/v1/chat/completions",
      "key": "ak_24E2Xr19A8gt8OL6KN0HG18z9XJ71",
      "model": "LongCat-Flash-Chat",
      "systemPrompt": "Act as a translation API. Output raw XML-like format only. No Markdown fences (xml). No conversational filler.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput Format:\n<root>\n    <t id=\"0\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n    <t id=\"1\" sourceLanguage=\"<detected_source_lang>\">Translated text content...</t>\n</root>\n\nRules:\n1.  **Strict Format**: Output ONLY the <root> element and its children. Do not include \"xml\" version declarations or markdown code blocks.\n2.  **Structure**: Maintain the exact \"id\" from the input in the \"id\" attribute. Detect the source language for the \"sourceLanguage\" attribute.\n3.  **HTML & Whitespace**: Preserve all HTML tags (e.g., <b>, <span>, <br>) and whitespace exactly as they appear in the structure. Only translate the text content inside them.\n4.  **Glossary**: Highest priority. Use the glossary value for translation. If the value is \"\", keep the source term as is.\n5.  **Do Not Translate**: Content inside <code>, <pre>, text in backticks (\"code\"), and placeholders like {1}, {{1}}, [1], [[1]].\n6.  **Context**: Use the \"title\" and \"description\" fields to understand the context for better translation accuracy, but do not output them.\n7.  **Tone**: Apply the specified \"tone\" (formal/casual).\n\nExample:\nInput:\n{\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":0,\"text\":\"Hello <b>World</b>!\"}],\"glossary\":{\"World\":\"世界\"},\"tone\":\"formal\"}\n\nOutput:\n<root>\n    <t id=\"0\" sourceLanguage=\"en\">你好 <b>世界</b>！</t>\n</root>",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "nobatchPrompt": "You are a professional, authentic machine translation engine.",
      "nobatchUserPrompt": "Translate the following source text to {{to}}. Output translation directly without any additional text.\n\nSource Text: {{text}}\n\nTranslated Text:",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 30000,
      "batchInterval": 400,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "isDisabled": false,
      "region": ""
    }
  ],
  "shortcuts": {
    "toggleTranslate": [
      "AltLeft",
      "KeyQ"
    ],
    "toggleStyle": [
      "AltLeft",
      "KeyC"
    ],
    "togglePopup": [
      "AltLeft",
      "KeyK"
    ],
    "openSetting": [
      "AltLeft",
      "KeyO"
    ]
  },
  "inputRule": {
    "transOpen": true,
    "apiSlug": "Microsoft",
    "fromLang": "auto",
    "toLang": "zh-CN",
    "triggerShortcut": [
      "AltLeft",
      "KeyI"
    ],
    "triggerCount": 1,
    "triggerTime": 200,
    "transSign": "/"
  },
  "tranboxSetting": {
    "transOpen": true,
    "apiSlugs": [
      "Microsoft"
    ],
    "fromLang": "auto",
    "toLang": "zh-CN",
    "toLang2": "en",
    "tranboxShortcut": [
      "AltLeft",
      "KeyS"
    ],
    "btnOffsetX": 10,
    "btnOffsetY": 10,
    "boxOffsetX": 0,
    "boxOffsetY": 10,
    "hideTranBtn": false,
    "hideClickAway": false,
    "simpleStyle": false,
    "followSelection": false,
    "autoHeight": false,
    "triggerMode": "click",
    "enDict": "Bing",
    "enSug": "Youdao"
  },
  "touchModes": [
    2
  ],
  "blacklist": "https://fishjar.github.io/kiss-translator/options.html,\nhttps://translate.google.com,\nhttps://www.deepl.com/translator",
  "csplist": "",
  "orilist": "https://dict.youdao.com",
  "skipLangs": [],
  "transInterval": 100,
  "langDetector": "-",
  "mouseHoverSetting": {
    "useMouseHover": false,
    "mouseHoverKey": [
      "ControlLeft"
    ]
  },
  "preInit": true,
  "transAllnow": false,
  "subtitleSetting": {
    "enabled": true,
    "apiSlug": "Microsoft",
    "segSlug": "-",
    "chunkLength": 1000,
    "preTrans": 90,
    "throttleTrans": 30,
    "toLang": "zh-CN",
    "isBilingual": true,
    "skipAd": false,
    "windowStyle": "padding: 0.5em 1em;\nbackground-color: rgba(0, 0, 0, 0.5);\ncolor: white;\nline-height: 1.3;\ntext-shadow: 1px 1px 2px black;\ndisplay: inline-block",
    "originStyle": "font-size: clamp(1rem, 2cqw, 3rem);",
    "translationStyle": "font-size: clamp(1rem, 2cqw, 3rem);",
    "isEnhance": true
  },
  "logLevel": 1,
  "rootMargin": 500,
  "customStyles": [
    {
      "styleSlug": "custom",
      "styleName": "Custom Style",
      "styleCode": "color: #209CEE;"
    }
  ]
}